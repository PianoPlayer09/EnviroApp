{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6256e27a-08ed-4176-95ec-cd303dc35727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbddc1ca-d954-4c2e-a8c6-bc1a5f9ef4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_images_sklearn(source_dir, train_dir, val_dir, test_dir, val_size = 0.2, test_size = 0.2, seed=32):\n",
    "    classes = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
    "\n",
    "    for class_name in classes:\n",
    "        train_class_dir = os.path.join(train_dir, class_name)\n",
    "        val_class_dir = os.path.join(val_dir, class_name)\n",
    "        test_class_dir = os.path.join(test_dir, class_name)\n",
    "        os.makedirs(train_class_dir, exist_ok=True)\n",
    "        os.makedirs(val_class_dir, exist_ok=True)\n",
    "        os.makedirs(test_class_dir, exist_ok=True)\n",
    "\n",
    "        class_folder = os.path.join(source_dir, class_name)\n",
    "        images = [f for f in os.listdir(class_folder) if os.path.isfile(os.path.join(class_folder, f))]\n",
    "\n",
    "        train_val_imgs, test_imgs = train_test_split(images, test_size=test_size, random_state=seed)\n",
    "\n",
    "        val_ratio = val_size / (1-test_size)\n",
    "        train_imgs, val_imgs = train_test_split(train_val_imgs, test_size = val_ratio, random_state=seed)\n",
    "\n",
    "        for img in train_imgs:\n",
    "            shutil.copy(os.path.join(class_folder, img), os.path.join(train_class_dir, img))\n",
    "        for img in val_imgs:\n",
    "            shutil.copy(os.path.join(class_folder, img), os.path.join(val_class_dir, img))\n",
    "        for img in test_imgs:\n",
    "            shutil.copy(os.path.join(class_folder, img), os.path.join(test_class_dir, img))\n",
    "\n",
    "source_dir = r'C:\\Users\\jagat\\Downloads\\archive\\Garbage classification\\Garbage classification'\n",
    "train_dir = r'Garbage classification/train'\n",
    "val_dir = r'Garbage classification/val'\n",
    "test_dir = r'Garbage classification/test'\n",
    "split_images_sklearn(source_dir, train_dir, val_dir, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9b016d-8eb9-4535-bcb5-66dd0e1df7c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# train_compute_transform = transforms.Compose([transforms.Resize((256, 192)),\n",
    "#                                transforms.ToTensor(),])\n",
    "\n",
    "# train_dataset = datasets.ImageFolder('Garbage classification/train', transform = train_compute_transform)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ffb015-4fc6-45dc-bacf-fbe66cac4852",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# mean = 0.0\n",
    "# std = 0.0\n",
    "# nb_samples = 0\n",
    "\n",
    "# for data, _ in train_loader:\n",
    "#     batch_samples = data.size(0)\n",
    "#     data = data.view(batch_samples, data.size(1), -1)\n",
    "\n",
    "#     mean += data.mean(2).sum(0)\n",
    "#     std += data.std(2).sum(0)\n",
    "#     nb_samples += batch_samples\n",
    "\n",
    "# mean /= nb_samples\n",
    "# std /= nb_samples\n",
    "\n",
    "# print(f\"Computed Mean: {mean}\")\n",
    "# print(f\"Computed Std: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40bdf4c1-3fe2-4a2c-9d27-055b8e316136",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e21f5ad3-0a5f-407f-8aca-7422a4d11cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder('Garbage classification/train', transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder('Garbage classification/val', transform=val_transform)\n",
    "test_dataset = datasets.ImageFolder('Garbage classification/test', transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size = 32, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5c2880d-5f71-4dfc-b865-a83bba05e705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:  6\n",
      "Class names:  ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n"
     ]
    }
   ],
   "source": [
    "dataset_sizes = {\n",
    "    'train': len(train_dataset),\n",
    "    'val': len(val_dataset),\n",
    "    'test': len(test_dataset)\n",
    "}\n",
    "class_names = train_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(\"Number of classes: \", num_classes)\n",
    "print(\"Class names: \", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "190d377f-bd00-4920-95e9-5d7feea3956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=10):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch{epoch+1}/{num_epochs}\")\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                dataloader = train_loader\n",
    "            else:\n",
    "                model.eval()\n",
    "                dataloader = val_loader\n",
    "\n",
    "            running_loss = 0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloader:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss/dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            print(f\"{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f\"Training complete in {time_elapsed//60:.0f}m {time_elapsed%60:.0f}s\")\n",
    "    print(f\"Best Validation Accuracy: {best_acc:.4f}\")\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "def test_model(model):\n",
    "    model.eval()\n",
    "    running_corrects = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    test_acc = running_corrects.double() / dataset_sizes['test']\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b040b22f-7534-418f-9e4b-a14a8bb562bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jagat\\anaconda3\\envs\\hands_on_ml\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jagat\\anaconda3\\envs\\hands_on_ml\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\jagat/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# models\n",
    "\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "num_ftrs = resnet_model.fc.in_features\n",
    "resnet_model.fc = nn.Linear(num_ftrs, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3903e12-6f2e-4a7b-bd5f-2795706635ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a7b4e0d-ea12-4205-8d35-d89ef1971037",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_optimizer = torch.optim.Adam(resnet_model.parameters(), lr=0.000055)\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34a82e59-892c-4eb8-8da5-7e1b69276665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Resnet 50\n",
      "Epoch1/5\n",
      "Train Loss: 0.9242 Acc: 0.6885\n",
      "Train Loss: 0.9242 Acc: 0.6885\n",
      "Val Loss: 0.4137 Acc: 0.8659\n",
      "Epoch2/5\n",
      "Val Loss: 0.4137 Acc: 0.8659\n",
      "Epoch2/5\n",
      "Train Loss: 0.2472 Acc: 0.9339\n",
      "Train Loss: 0.2472 Acc: 0.9339\n",
      "Val Loss: 0.3301 Acc: 0.8955\n",
      "Epoch3/5\n",
      "Val Loss: 0.3301 Acc: 0.8955\n",
      "Epoch3/5\n",
      "Train Loss: 0.1128 Acc: 0.9749\n",
      "Train Loss: 0.1128 Acc: 0.9749\n",
      "Val Loss: 0.2373 Acc: 0.9270\n",
      "Epoch4/5\n",
      "Val Loss: 0.2373 Acc: 0.9270\n",
      "Epoch4/5\n",
      "Train Loss: 0.0722 Acc: 0.9828\n",
      "Train Loss: 0.0722 Acc: 0.9828\n",
      "Val Loss: 0.2227 Acc: 0.9329\n",
      "Epoch5/5\n",
      "Val Loss: 0.2227 Acc: 0.9329\n",
      "Epoch5/5\n",
      "Train Loss: 0.0422 Acc: 0.9927\n",
      "Train Loss: 0.0422 Acc: 0.9927\n",
      "Val Loss: 0.2052 Acc: 0.9349\n",
      "Training complete in 10m 42s\n",
      "Best Validation Accuracy: 0.9349\n",
      "Testing Resnet 50\n",
      "Val Loss: 0.2052 Acc: 0.9349\n",
      "Training complete in 10m 42s\n",
      "Best Validation Accuracy: 0.9349\n",
      "Testing Resnet 50\n",
      "Test Accuracy: 0.9370\n",
      "Test Accuracy: 0.9370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9370, dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training Resnet 50\")\n",
    "resnet_model = train_model(resnet_model, criterion, resnet_optimizer, num_epochs = 5)\n",
    "print(\"Testing Resnet 50\")\n",
    "test_model(resnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8e1a57b-0dde-4189-b736-d990dafb3724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Resnet 50\n",
      "Test Accuracy: 0.9370\n",
      "Test Accuracy: 0.9370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9370, dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Testing Resnet 50\")\n",
    "test_model(resnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "598f5176-c048-4f44-bcee-56ffbbad9e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train classes: {'cardboard': 0, 'glass': 1, 'metal': 2, 'paper': 3, 'plastic': 4, 'trash': 5}\n",
      "Test classes: {'cardboard': 0, 'glass': 1, 'metal': 2, 'paper': 3, 'plastic': 4, 'trash': 5}\n"
     ]
    }
   ],
   "source": [
    "print(\"Train classes:\", train_dataset.class_to_idx)\n",
    "print(\"Test classes:\", test_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "045c30b3-2a27-47d2-8392-7294f66d3d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15e0d7ec-9b74-44e7-ab64-a31928e599f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(resnet_model, 'model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700e117a-a31f-4469-ab3b-fc8a6d1e3c35",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[1;32m      3\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrestnet_model\u001b[39m\u001b[38;5;124m'\u001b[39m, resnet_model)])\n\u001b[0;32m----> 4\u001b[0m pipe\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# pipe = Pipeline([('restnet_model', resnet_model)])\n",
    "# pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2354efa-0848-47dd-8a23-c0f9732fd82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# at the end of your training script\n",
    "torch.save(resnet_model.state_dict(), \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3b6664-2c9f-44cb-84ad-43f7bd3dc318",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hands_on_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
